# analyze_and_store.py
import json
import sqlite3
import matplotlib.pyplot as plt
import numpy as np
from typing import Dict, List, Tuple
import os
import csv
import matplotlib

# =================== è®¾ç½®ä¸­æ–‡å­—ä½“ ===================
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·
matplotlib.use('Agg')

# =================== é…ç½® ===================
INPUT_FILE = "results.json"
DB_FILE = "elder_care.db"
PLOT_DIR = "plots"
CSV_FILE = "elder_care.csv"
os.makedirs(PLOT_DIR, exist_ok=True)


# =================== æ•°æ®åº“åˆå§‹åŒ– ===================
def init_database():
    """åˆ›å»º SQLite æ•°æ®åº“å’Œè¡¨"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    cursor.execute('''
        CREATE TABLE IF NOT EXISTS predictions (
            user_id TEXT PRIMARY KEY,
            normal REAL,
            fatigue REAL,
            heart_abnormal REAL,
            high_bp REAL,
            low_o2 REAL,
            low_mood REAL,
            fall_risk REAL,
            cognitive_risk REAL,
            primary_risk TEXT,
            risk_level TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')

    conn.commit()
    conn.close()


# =================== é«˜é£é™©ç­›é€‰è§„åˆ™ ===================
def classify_risk(user_id: str, probs: Dict[str, float]) -> Tuple[str, str]:
    states = list(probs.keys())
    values = list(probs.values())
    primary_risk = states[np.argmax(values)]
    max_prob = max(values)

    multi_risk_count = len([v for v in probs.values() if v > 0.12]) >= 3

    if max_prob > 0.20 or multi_risk_count:
        risk_level = "é«˜é£é™©"
    elif max_prob > 0.15 or len([v for v in probs.values() if v > 0.15]) >= 2:
        risk_level = "ä¸­é£é™©"
    else:
        risk_level = "ä½é£é™©"

    return primary_risk, risk_level


# =================== å­˜å…¥æ•°æ®åº“ ===================
def save_to_db(data: List[Dict]):
    """å°†åˆ†æç»“æœå­˜å…¥æ•°æ®åº“"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    for item in data:
        cursor.execute('''
            INSERT OR REPLACE INTO predictions 
            (user_id, normal, fatigue, heart_abnormal, high_bp, low_o2, 
             low_mood, fall_risk, cognitive_risk, primary_risk, risk_level)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            item['user_id'],
            item['probs']['æ­£å¸¸'],
            item['probs']['ç–²åŠ³'],
            item['probs']['å¿ƒç‡å¼‚å¸¸'],
            item['probs']['è¡€å‹åé«˜'],
            item['probs']['è¡€æ°§åä½'],
            item['probs']['æƒ…ç»ªä½è½'],
            item['probs']['è·Œå€’é£é™©ä¸­'],
            item['probs']['è®¤çŸ¥æ¨¡ç³Šæ—©æœŸå¾å…†'],
            item['primary_risk'],
            item['risk_level']
        ))

    conn.commit()
    conn.close()
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {DB_FILE}")


# =================== å¯¼å‡º CSV æ–‡ä»¶===================
def export_csv():
    """ä»æ•°æ®åº“å¯¼å‡º CSV æ–‡ä»¶ï¼Œå¸¦ UTF-8 with BOMï¼Œç¡®ä¿ Excel æ­£ç¡®è¯†åˆ«"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    cursor.execute("SELECT * FROM predictions")
    rows = cursor.fetchall()
    columns = [description[0] for description in cursor.description]

    # utf-8ç¼–ç ï¼Œè‡ªåŠ¨æ·»åŠ BOMï¼ŒExcelå¯æ­£ç¡®è¯†åˆ«ä¸­æ–‡
    with open(CSV_FILE, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(columns)
        writer.writerows(rows)

    conn.close()
    print(f"âœ… æ•°æ®å·²å¯¼å‡ºä¸º CSV æ–‡ä»¶ï¼ˆExcel å‹å¥½ï¼‰: {CSV_FILE}")


# =================== å¯è§†åŒ–ï¼šæŸ±çŠ¶å›¾ ===================
def plot_group_bar(all_data: List[Dict]):
    """ç»˜åˆ¶å„ç±»é£é™©çš„å¹³å‡æ¦‚ç‡"""
    labels = ["æ­£å¸¸", "ç–²åŠ³", "å¿ƒç‡å¼‚å¸¸", "è¡€å‹åé«˜", "è¡€æ°§åä½", "æƒ…ç»ªä½è½", "è·Œå€’é£é™©ä¸­", "è®¤çŸ¥æ¨¡ç³Šæ—©æœŸå¾å…†"]
    avg_probs = [np.mean([d['probs'][label] for d in all_data]) for label in labels]

    plt.figure(figsize=(10, 6))
    plt.bar(labels, avg_probs, color='skyblue', edgecolor='navy', alpha=0.8)
    plt.title("ç¾¤ä½“å¥åº·çŠ¶æ€å¹³å‡æ¦‚ç‡åˆ†å¸ƒ")
    plt.ylabel("æ¦‚ç‡")
    plt.xticks(rotation=45)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{PLOT_DIR}/group_risk_distribution.png", dpi=150, bbox_inches='tight')
    plt.close()
    print("ğŸ“Š ç¾¤ä½“åˆ†å¸ƒå›¾å·²ç”Ÿæˆ")


# =================== å¯è§†åŒ–ï¼šä¸ªäººé›·è¾¾å›¾ ===================
def plot_radar(user_id: str, probs: Dict[str, float]):
    """ç»˜åˆ¶å•ä¸ªç”¨æˆ·çš„é›·è¾¾å›¾"""
    labels = ["æ­£å¸¸", "ç–²åŠ³", "å¿ƒç‡å¼‚å¸¸", "è¡€å‹åé«˜", "è¡€æ°§åä½", "æƒ…ç»ªä½è½", "è·Œå€’é£é™©ä¸­", "è®¤çŸ¥æ¨¡ç³Šæ—©æœŸå¾å…†"]
    values = [probs[label] for label in labels]

    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
    values += values[:1]
    angles += angles[:1]

    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
    ax.fill(angles, values, color='red', alpha=0.25)
    ax.plot(angles, values, color='red', linewidth=2)
    ax.set_yticklabels([])
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(labels, fontsize=10, fontweight='bold')
    plt.title(f"å¥åº·é£é™©é›·è¾¾å›¾: {user_id}", pad=20, fontsize=12, fontweight='bold')

    plt.tight_layout()
    plt.savefig(f"{PLOT_DIR}/{user_id}_radar.png", dpi=150, bbox_inches='tight', pad_inches=0.1)
    plt.close()


def main():
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            raw_results = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å– {INPUT_FILE} å¤±è´¥: {e}")
        return

    analyzed_data = []
    high_risk_list = []
    mid_risk_list = []

    for user_id, probs in raw_results.items():
        if "error" in probs:
            continue

        primary_risk, risk_level = classify_risk(user_id, probs)
        item = {
            "user_id": user_id,
            "probs": probs,
            "primary_risk": primary_risk,
            "risk_level": risk_level
        }
        analyzed_data.append(item)

        if risk_level == "é«˜é£é™©":
            high_risk_list.append(item)
        elif risk_level == "ä¸­é£é™©":
            mid_risk_list.append(item)

        plot_radar(user_id, probs)

    plot_group_bar(analyzed_data)
    init_database()
    save_to_db(analyzed_data)
    export_csv()

    print("\n" + "="*50)
    print("              ğŸš¨ é«˜é£é™©ç”¨æˆ·æŠ¥å‘Š")
    print("="*50)
    print(f"ğŸ“Š æ€»äººæ•°: {len(analyzed_data)}")
    print(f"ğŸ”´ é«˜é£é™©: {len(high_risk_list)} äºº")
    print(f"ğŸŸ¡ ä¸­é£é™©: {len(mid_risk_list)} äºº")
    print(f"ğŸŸ¢ ä½é£é™©: {len(analyzed_data) - len(high_risk_list) - len(mid_risk_list)} äºº")
    print("\nğŸ”´ é«˜é£é™©ç”¨æˆ·:")
    for item in high_risk_list:
        print(f"   {item['user_id']} â†’ ä¸»è¦é£é™©: {item['primary_risk']}")

    with open("high_risk_elders.json", "w", encoding="utf-8") as f:
        json.dump(high_risk_list, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… é«˜é£é™©åå•å·²ä¿å­˜: high_risk_elders.json")
    print(f"âœ… æ‰€æœ‰é›·è¾¾å›¾å·²ä¿å­˜è‡³: {PLOT_DIR}/")
    print(f"âœ… æ•°æ®åº“å·²æ›´æ–°: {DB_FILE}")
    print(f"âœ… æ•°æ®å·²å¯¼å‡ºä¸º CSV æ–‡ä»¶ï¼ˆExcel å¯è¯»ï¼‰: {CSV_FILE}")


if __name__ == "__main__":
    main()